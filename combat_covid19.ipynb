{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "combat-covid19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sdalsa/combat_covid19/blob/main/combat_covid19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU8ODp3eBAIS"
      },
      "source": [
        "# Q: What is the likelihood of mortality in patient caused by covid19?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "HvqvsTjiBAIT"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        os.path.join(dirname, filename)\n",
        "\n",
        "# Load data \n",
        "cov_dash_country = pd.read_csv('../input/uncover/UNCOVER_v4/UNCOVER/johns_hopkins_csse/johns-hopkins-covid-19-daily-dashboard-cases-by-country.csv');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DrG8r4qGBAIT"
      },
      "source": [
        "cov_dash_country"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mKKOl7iVBAIT"
      },
      "source": [
        "cov_dash_country.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odM_aJDqBAIT"
      },
      "source": [
        "## Defining feature and target "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Mzt2KfDBBAIT"
      },
      "source": [
        "y = cov_dash_country['mortality_rate']\n",
        "X = cov_dash_country.drop(['mortality_rate'], axis=1)\n",
        "print(' Loaded target:', y.name, '\\n Loaded features:', X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxo-lDezBAIT"
      },
      "source": [
        "## Splitting the data into train and validation set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "66uXwvd_BAIT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4gahK9NBAIU"
      },
      "source": [
        "## Seperating categorical data from numerical data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V5bkPUJLBAIU"
      },
      "source": [
        "categorical_cols = [cat for cat in X_train.columns if X_train[cat].dtype=='object']\n",
        "numerical_cols = [num for num in X_train.columns if X_train[num].dtype in ['int64', 'float64']]\n",
        "'Successful separation of cat and num data: {}' .format((len(numerical_cols + categorical_cols) - len(X_train.columns)==0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_sLlhepBAIU"
      },
      "source": [
        "## Bundle preprocessed data (numerical and categorical)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ptds8QkbBAIU"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer \n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.impute import SimpleImputer \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "numerical_transformer = SimpleImputer(strategy = \"constant\")\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')), \n",
        "                                              ('onehot', OneHotEncoder(handle_unknown='ignore')) ])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer( transformers=[ ('num', numerical_transformer, numerical_cols), \n",
        "                                                ('cat', categorical_transformer, categorical_cols) ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIqVNIW2BAIU"
      },
      "source": [
        "## Defining the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Trz4lZd2BAIU"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def testmodels (model):\n",
        "    #bundle preprocessing and modeling code in a pipeline\n",
        "    my_pipeline = Pipeline(steps = [('preprocessing', preprocessor), ('model', model) ])\n",
        "    #preprocessing of training data, and fit model\n",
        "    my_pipeline.fit(X_train, y_train)\n",
        "    #Preprocessing to get prediction\n",
        "    preds = my_pipeline.predict(X_valid)\n",
        "    #evaluate the model\n",
        "    score = mean_absolute_error(y_valid, preds)\n",
        "    \n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zH-gWIuBAIU"
      },
      "source": [
        "## Testing ML models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5N97RdSFBAIU"
      },
      "source": [
        "# import models \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "# defining different models \n",
        "rfr_model_0 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
        "rfr_model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
        "rfr_model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "rfr_model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\n",
        "rfr_model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
        "\n",
        "\n",
        "xgb_model_5 = xgb.XGBRegressor()\n",
        "xgb_model_6 = xgb.XGBClassifier(max_depth=20,n_estimators=2020,colsample_bytree=0.20,learning_rate=0.020,objective='binary:logistic', n_jobs=-1)\n",
        "xgb_model_7 = xgb.XGBClassifier(n_estimators=100,learning_rate=0.020)\n",
        "\n",
        "\n",
        "models = [rfr_model_0, rfr_model_1, rfr_model_2, rfr_model_3, rfr_model_4, \n",
        "          xgb_model_5, xgb_model_6, xgb_model_7]\n",
        "\n",
        "# testing and saving the best model\n",
        "model_performance = {}\n",
        "for idx, model in enumerate(models):        \n",
        "    model_performance.update({models[idx]:testmodels(model)})\n",
        "    print(\"mae: {} --> Model number {}\".format(testmodels(model), str(idx)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlBtbdCCBAIV"
      },
      "source": [
        "## Final model, saved "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pZgJjN1pBAIV"
      },
      "source": [
        "final_model = Pipeline(steps = [('preprocessing', preprocessor), ('model', min(model_performance, key=model_performance.get))])\n",
        "final_model.fit(X_train, y_train)\n",
        "preds = final_model.predict(X_valid)\n",
        "score = mean_absolute_error(y_valid, preds)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}